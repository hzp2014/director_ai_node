import axios from 'axios';
import settings from './config.js';
import logger from './logger.js';

class ChatMessage {
  constructor(role, content, reasoningContent = null, toolCalls = null) {
    this.role = role;
    this.content = content;
    this.reasoningContent = reasoningContent;
    this.toolCalls = toolCalls;
  }

  toJson() {
    const data = {
      role: this.role,
      content: this.content
    };

    if (this.reasoningContent) {
      data.reasoning_content = this.reasoningContent;
    }

    if (this.toolCalls) {
      data.tool_calls = this.toolCalls;
    }

    return data;
  }
}

class StreamChunk {
  constructor({ isContent = false, isReasoning = false, text = '', toolCalls = null } = {}) {
    this.isContent = isContent;
    this.isReasoning = isReasoning;
    this.text = text;
    this.toolCalls = toolCalls;
  }
}

class AIClient {
  constructor() {
    this.zhipuClient = axios.create({
      baseURL: settings.zhipuApiBaseUrl,
      headers: {
        'Authorization': `Bearer ${settings.zhipuApiKey}`,
        'Content-Type': 'application/json'
      },
      timeout: 300000
    });

    this.doubaoClient = axios.create({
      baseURL: settings.doubaoApiBaseUrl,
      headers: {
        'Authorization': `Bearer ${settings.doubaoApiKey}`,
        'Content-Type': 'application/json'
      },
      timeout: 120000
    });
  }

  async sendToGLMStream(messages, model = settings.defaultChatModel, temperature = 0.7, maxTokens = 4096) {
    if (settings.useMockChatApi) {
      logger.warn('GLMå¯¹è¯', 'ğŸ§ª ä½¿ç”¨ Mock æ¨¡å¼');
      return this._mockStream(messages);
    }

    const requestData = {
      model: model,
      messages: messages.map(msg => msg.toJson ? msg.toJson() : msg),
      stream: true,
      temperature: temperature,
      max_tokens: maxTokens
    };

    logger.info('GLMå¯¹è¯', `å‘é€è¯·æ±‚åˆ° ${model}, æ¶ˆæ¯æ•°é‡: ${messages.length}`);
    logger.debug('GLMå¯¹è¯', `è¯·æ±‚ä½“: ${JSON.stringify(requestData, null, 2)}`);

    try {
      const response = await this.zhipuClient.post('/chat/completions', requestData, {
        responseType: 'stream'
      });

      const chunks = [];

      for await (const chunk of response.data) {
        const lines = chunk.toString().split('\n').filter(line => line.trim());

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const dataStr = line.slice(6);

            if (dataStr === '[DONE]') {
              continue;
            }

            try {
              const data = JSON.parse(dataStr);
              const streamChunk = this._parseStreamChunk(data);
              if (streamChunk) {
                chunks.push(streamChunk);
              }
            } catch (error) {
              logger.warn('GLMå¯¹è¯', `è§£æchunkå¤±è´¥: ${error.message}`);
            }
          }
        }
      }

      logger.success('GLMå¯¹è¯', `æ”¶åˆ° ${chunks.length} ä¸ªchunks`);
      return chunks;
    } catch (error) {
      logger.error('GLMå¯¹è¯', `è¯·æ±‚å¤±è´¥: ${error.message}`);
      throw new Error(`GLMè¯·æ±‚å¤±è´¥: ${error.message}`);
    }
  }

  async sendToGLM(messages, model = settings.defaultChatModel, temperature = 0.7, maxTokens = 4096) {
    if (settings.useMockChatApi) {
      logger.warn('GLMå¯¹è¯', 'ğŸ§ª ä½¿ç”¨ Mock æ¨¡å¼');
      const chunks = await this._mockStream(messages);
      return chunks.map(chunk => chunk.text).join('');
    }

    const requestData = {
      model: model,
      messages: messages.map(msg => msg.toJson ? msg.toJson() : msg),
      stream: false,
      temperature: temperature,
      max_tokens: maxTokens
    };

    logger.info('GLMå¯¹è¯', `å‘é€è¯·æ±‚åˆ° ${model}, æ¶ˆæ¯æ•°é‡: ${messages.length}`);

    try {
      const response = await this.zhipuClient.post('/chat/completions', requestData);
      const data = response.data;

      logger.success('GLMå¯¹è¯', `æ”¶åˆ°å“åº”`);

      const choice = data.choices && data.choices[0];
      if (!choice) {
        throw new Error('å“åº”æ ¼å¼é”™è¯¯: æ²¡æœ‰choices');
      }

      const message = choice.message;
      return message.content || '';
    } catch (error) {
      logger.error('GLMå¯¹è¯', `è¯·æ±‚å¤±è´¥: ${error.message}`);
      throw new Error(`GLMè¯·æ±‚å¤±è´¥: ${error.message}`);
    }
  }

  async analyzeImageForCharacter(imageBase64, mimeType = 'image/jpeg') {
    if (settings.doubaoApiKey === '') {
      throw new Error('è±†åŒ… API Key æœªè®¾ç½®ï¼Œæ— æ³•è¿›è¡Œå›¾ç‰‡åˆ†æ');
    }

    const prompt = `è¯·ä»”ç»†è§‚å¯Ÿè¿™å¼ å›¾ç‰‡ï¼Œæå–å…¶ä¸­ä¸»è¦è§’è‰²æˆ–äººç‰©çš„è¯¦ç»†ç‰¹å¾æè¿°ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼ˆåªè¿”å›æè¿°ï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰ï¼š

**å¤–è§‚ç‰¹å¾**ï¼š[è¯¦ç»†æè¿°è§’è‰²çš„å¤–è§‚ï¼ŒåŒ…æ‹¬ï¼šå‘å‹ã€å‘è‰²ã€é¢éƒ¨ç‰¹å¾ã€çœ¼ç›é¢œè‰²ã€çš®è‚¤çŠ¶æ€ã€ä½“å‹ç­‰]

**ç©¿ç€æ‰“æ‰®**ï¼š[æè¿°è§’è‰²çš„æœè£…é£æ ¼ã€é¢œè‰²ã€é…é¥°ç­‰]

**å§¿æ€è¡¨æƒ…**ï¼š[æè¿°è§’è‰²çš„å§¿æ€ã€è¡¨æƒ…ã€æ°”è´¨ç­‰]

**æ•´ä½“é£æ ¼**ï¼š[ä¸€å¥è¯æ€»ç»“è¿™ä¸ªè§’è‰²çš„æ•´ä½“è§†è§‰é£æ ¼]

è¯·ç¡®ä¿æè¿°è¶³å¤Ÿè¯¦ç»†ï¼Œä»¥ä¾¿åç»­å¯ä»¥æ ¹æ®è¿™äº›æè¿°ç”Ÿæˆä¸€è‡´çš„è§’è‰²å½¢è±¡ã€‚`;

    const requestData = {
      model: settings.defaultImageModel,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image_url',
              image_url: {
                url: `data:${mimeType};base64,${imageBase64}`
              }
            },
            {
              type: 'text',
              text: prompt
            }
          ]
        }
      ]
    };

    logger.info('è±†åŒ…-ARK', 'å¼€å§‹åˆ†æå›¾ç‰‡ç‰¹å¾...');
    logger.debug('è±†åŒ…-ARK', `è¯·æ±‚ä½“: ${JSON.stringify(requestData, null, 2)}`);

    try {
      const response = await this.doubaoClient.post('/chat/completions', requestData);
      const data = response.data;

      const choices = data.choices;
      if (!choices || choices.length === 0) {
        logger.error('è±†åŒ…-ARK', 'å“åº”æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰ choices');
        throw new Error('å›¾ç‰‡åˆ†æå¤±è´¥ï¼šå“åº”æ ¼å¼é”™è¯¯');
      }

      const firstChoice = choices[0];
      const message = firstChoice.message;
      const content = message && message.content;

      if (!content) {
        logger.error('è±†åŒ…-ARK', 'å›¾ç‰‡åˆ†æå“åº”ä¸ºç©º');
        throw new Error('å›¾ç‰‡åˆ†æå¤±è´¥ï¼šå“åº”ä¸ºç©º');
      }

      logger.success('è±†åŒ…-ARK', 'å›¾ç‰‡åˆ†æå®Œæˆ');
      logger.info('è±†åŒ…-ARK', `æå–çš„ç‰¹å¾:\n${content}`);

      return content;
    } catch (error) {
      logger.error('è±†åŒ…-ARK', `å›¾ç‰‡åˆ†æå¤±è´¥: ${error.message}`);
      throw new Error(`å›¾ç‰‡åˆ†æå¤±è´¥: ${error.message}`);
    }
  }

  async rewriteVideoPromptForSafety(originalPrompt, sceneNarration) {
    logger.info('æç¤ºè¯é‡å†™', `åŸå§‹æç¤ºè¯: ${originalPrompt}`);
    logger.info('æç¤ºè¯é‡å†™', `åœºæ™¯æ—ç™½: ${sceneNarration}`);

    const rewritePrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘æç¤ºè¯ä¼˜åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†è§†é¢‘æç¤ºè¯é‡å†™ä¸º100%å®‰å…¨çš„è¡¨è¾¾æ–¹å¼ï¼Œç¡®ä¿é€šè¿‡å¹³å°çš„å†…å®¹å®¡æ ¸ã€‚

**åŸå§‹åœºæ™¯æ—ç™½**:
${sceneNarration}

**åŸå§‹è§†é¢‘æç¤ºè¯**:
${originalPrompt}

**è¦æ±‚**:
1. ä¿æŒåŸæ„ä¸å˜ï¼Œåªè°ƒæ•´è¡¨è¾¾æ–¹å¼
2. ç§»é™¤æ‰€æœ‰å¯èƒ½è§¦å‘å†…å®¹å®¡æ ¸çš„æ•æ„Ÿè¯æ±‡
3. ä½¿ç”¨ç§¯ææ­£å‘çš„è¯æ±‡æ›¿æ¢
4. ç¡®ä¿æç¤ºè¯ç®€æ´æ¸…æ™°ï¼Œé€‚åˆè§†é¢‘ç”Ÿæˆ
5. åªè¿”å›é‡å†™åçš„æç¤ºè¯ï¼Œä¸è¦å…¶ä»–å†…å®¹

**é‡å†™åçš„æç¤ºè¯**:`;

    const messages = [
      { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘æç¤ºè¯ä¼˜åŒ–ä¸“å®¶ï¼Œæ“…é•¿å°†æç¤ºè¯é‡å†™ä¸ºå®‰å…¨çš„è¡¨è¾¾æ–¹å¼ã€‚' },
      { role: 'user', content: rewritePrompt }
    ];

    try {
      const rewrittenPrompt = await this.sendToGLM(messages);
      logger.success('æç¤ºè¯é‡å†™', `é‡å†™å®Œæˆ`);
      logger.info('æç¤ºè¯é‡å†™', `é‡å†™åæç¤ºè¯: ${rewrittenPrompt}`);
      return rewrittenPrompt;
    } catch (error) {
      logger.error('æç¤ºè¯é‡å†™', `é‡å†™å¤±è´¥: ${error.message}`);
      logger.warn('æç¤ºè¯é‡å†™', 'ä½¿ç”¨åŸå§‹æç¤ºè¯');
      return originalPrompt;
    }
  }

  _parseStreamChunk(data) {
    if (!data.choices || data.choices.length === 0) {
      return null;
    }

    const choice = data.choices[0];
    const delta = choice.delta;

    if (!delta) {
      return null;
    }

    const chunk = new StreamChunk();

    if (delta.reasoning_content || delta.reasoning_content === '') {
      chunk.isReasoning = true;
      chunk.text = delta.reasoning_content || '';
    } else if (delta.content || delta.content === '') {
      chunk.isContent = true;
      chunk.text = delta.content || '';
    } else if (delta.tool_calls) {
      chunk.toolCalls = delta.tool_calls;
    }

    return chunk;
  }

  async _mockStream(messages) {
    const lastMessage = messages[messages.length - 1];
    const content = lastMessage.content || JSON.stringify(lastMessage);

    const mockContent = {
      'task_id': 'mock_task_' + Date.now(),
      'script_title': 'Mock å‰§æœ¬',
      'scenes': [
        {
          'scene_id': 1,
          'narration': 'è¿™æ˜¯ç¬¬ä¸€ä¸ªåœºæ™¯',
          'image_prompt': 'A beautiful scene with gentle light',
          'video_prompt': 'Smooth camera movement',
          'character_description': 'A young person with bright eyes'
        },
        {
          'scene_id': 2,
          'narration': 'è¿™æ˜¯ç¬¬äºŒä¸ªåœºæ™¯',
          'image_prompt': 'Another beautiful scene',
          'video_prompt': 'Calm atmosphere',
          'character_description': 'The same character from scene 1'
        }
      ]
    };

    const jsonStr = JSON.stringify(mockContent, null, 2);

    const chunks = [];

    for (let i = 0; i < jsonStr.length; i += 10) {
      const chunk = jsonStr.slice(i, i + 10);
      chunks.push(new StreamChunk({
        isContent: true,
        text: chunk
      }));
    }

    return chunks;
  }
}

const aiClient = new AIClient();

export { AIClient, ChatMessage, StreamChunk, aiClient };
export default aiClient;
